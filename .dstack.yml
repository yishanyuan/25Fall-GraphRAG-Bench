#Copy this to the root of the original project and run with "dstack apply"

type: task
name: fast-graphrag-ollama-test

repos:
  - https://github.com/yishanyuan/25Fall-GraphRAG-Bench

python: 3.12

ide: pycharm

env:
  - OPENAI_BASE_URL=http://127.0.0.1:11434/v1
  - OPENAI_API_KEY=ollama
  - MODEL_NAME=qwen3:8b

commands:
  # 1) Install Ollama in the remote container
  - curl -fsSL https://ollama.ai/install.sh | sh

  # 2) Start the Ollama server in the background
  - nohup ollama serve > /tmp/ollama.log 2>&1 &

  # 3) Give the server time to start
  - sleep 60

  # 4) Pull the Qwen3 8B model on dstack's machine
  - ollama pull qwen3:8b

  # 5) Install fast-graphrag
  - cd /workflow
  - uv pip install -e ".[benchmarks]"

  # 6) Run the test script against the local Ollama server
  - cd /workflow/benchmarks
  - python testrun_fast-graphrag_ollama.py -d 2wikimultihopqa -n 20 -c
  - python testrun_fast-graphrag_ollama.py -d 2wikimultihopqa -n 20 -b

resources:
  gpu: 24GB..80GB:1
  cpu: 0..8
  memory: 48GB..
  disk: 100GB
  shm_size: 24GB

